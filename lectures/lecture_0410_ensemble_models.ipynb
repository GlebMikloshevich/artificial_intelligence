{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96dfd9b5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest\n",
    "1. Bagging - обучение дерева на датасете из случайных строк изначального датасета. Строки могут пересекаться, а могут не пересекаться\n",
    "2. Random subspaces - использует произвольные столбцы. Таким способом обучение происходит быстрее, а дерево становиться более устойчивым\n",
    "3. Random patches - использует произвольные строки и произвольные столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c6bb07",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier, StackingClassifier, AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import sklearn.datasets as sd\n",
    "import sklearn.model_selection as sm\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bafdddb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_dat_path = '../datasets/test_add_forest.dat'\n",
    "\n",
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "XARR1 = []\n",
    "XARR2 = []\n",
    "XARR3 = []\n",
    "XARR4 = []\n",
    "XARR5 = []\n",
    "y = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "\n",
    "        XARR1.append([cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], 0, 0])\n",
    "        XARR2.append([cols[0], cols[1], cols[2], cols[3], 0, 0, cols[6], cols[7], cols[8], cols[9]])\n",
    "        XARR3.append([0, 0, cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]])\n",
    "        XARR4.append([0, cols[1], cols[2], 0, cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]])\n",
    "        XARR5.append([cols[0], cols[1], cols[2], cols[3], 0, cols[5], cols[6], cols[7], cols[8], cols[9]])\n",
    "        y.append(cols[10])\n",
    "\n",
    "dt1 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "dt1 = dt1.fit(XARR1, y)\n",
    "\n",
    "dt2 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "dt2 = dt2.fit(XARR2, y)\n",
    "\n",
    "dt3 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "dt3 = dt3.fit(XARR3, y)\n",
    "\n",
    "dt4 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "dt4 = dt4.fit(XARR4, y)\n",
    "\n",
    "dt5 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "dt5 = dt5.fit(XARR5, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb26121",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.31963470319636 %\n",
      "good: 2861\n",
      "total: 4380\n"
     ]
    }
   ],
   "source": [
    "good = 0\n",
    "total = 0\n",
    "i = 0\n",
    "\n",
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "        EX = [cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]]\n",
    "        r1 = dt1.predict([EX])\n",
    "        r2 = dt2.predict([EX])\n",
    "        r3 = dt3.predict([EX])\n",
    "        r4 = dt4.predict([EX])\n",
    "        r5 = dt5.predict([EX])\n",
    "        z = int((int(r1[0]) + int(r2[0]) + int(r3[0]) + int(r4[0]) + int(r5[0])) / 5)\n",
    "\n",
    "        if z == int(cols[10]):\n",
    "            good += 1\n",
    "        total += 1\n",
    "\n",
    "print(str(good/ total * 100), '%')\n",
    "print(f'good: {good}')\n",
    "print(f'total: {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15509b83",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## BaggingClassifier from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6991d690",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7924657534246575\n"
     ]
    }
   ],
   "source": [
    "test_dat_path = '../datasets/test_add_forest.dat'\n",
    "\n",
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "        X.append([cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]])\n",
    "        y.append(cols[10])\n",
    "\n",
    "bagging_clf = BaggingClassifier(tree.DecisionTreeClassifier(max_depth=2), n_estimators=10)\n",
    "bagging_clf = bagging_clf.fit(X, y)\n",
    "\n",
    "print(bagging_clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092840e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Stacking\n",
    "**Stacking** - Для вычисления итогового результата обучается дополнительное решающее дерево, которое получает данные с деревьев первого этапа и выдает ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94f6c621",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_dat_path = '../datasets/test_add_forest.dat'\n",
    "\n",
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "XARR1 = []\n",
    "XARR2 = []\n",
    "\n",
    "y = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "\n",
    "        XARR1.append([cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], 0, 0])\n",
    "        XARR2.append([cols[0], cols[1], cols[2], cols[3], 0, 0, cols[6], cols[7], cols[8], cols[9]])\n",
    "        y.append(cols[10])\n",
    "\n",
    "dt1 = tree.DecisionTreeClassifier(max_depth=3)\n",
    "dt1 = dt1.fit(XARR1, y)\n",
    "\n",
    "dt2 = tree.DecisionTreeClassifier(max_depth=3)\n",
    "dt2 = dt2.fit(XARR2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d6ce19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "X2 = []\n",
    "y2 = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "        EX = [cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]]\n",
    "        r1 = dt1.predict([EX])\n",
    "        r2 = dt2.predict([EX])\n",
    "        X2.append([r1[0], r2[0]])\n",
    "        y2.append(cols[10])\n",
    "\n",
    "clf3 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "clf3.fit(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45319a4c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "good = 0\n",
    "total = 0\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "        EX = [cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]]\n",
    "        r1 = dt1.predict([EX])\n",
    "        r2 = dt2.predict([EX])\n",
    "        EX3 = [r1[0], r2[0]]\n",
    "        ans = clf3.predict([EX3])\n",
    "\n",
    "        if int(ans[0]) == int(cols[10]):\n",
    "            good += 1\n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6315028f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.20091324200914 %\n",
      "good: 3469\n",
      "total: 4380\n"
     ]
    }
   ],
   "source": [
    "print(str(good/ total * 100), '%')\n",
    "print(f'good: {good}')\n",
    "print(f'total: {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7ba972",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## StackingClassifier from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "598b86a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9164383561643835\n"
     ]
    }
   ],
   "source": [
    "test_dat_path = '../datasets/test_add_forest.dat'\n",
    "\n",
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "XARR3 = []\n",
    "\n",
    "y3 = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "\n",
    "        XARR3.append([cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]])\n",
    "        y3.append(cols[10])\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=[('t1', tree.DecisionTreeClassifier(max_depth=5)),\n",
    "                                              ('t2', tree.DecisionTreeClassifier(max_depth=5)),\n",
    "                                              ('t3', tree.DecisionTreeClassifier(max_depth=5))],\n",
    "                                  final_estimator=tree.DecisionTreeClassifier(max_depth=2))\n",
    "\n",
    "stacking_clf = stacking_clf.fit(XARR3, y3)\n",
    "print(stacking_clf.score(XARR3, y3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72505e7f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Boosting\n",
    "**Boosting** - обучаем новое дерево, которое получает на вход исходный датасет и ответ с деревьев первого слоя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170f89d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Добавить код для бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9872fda7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_dat_path = '../datasets/test_add_forest.dat'\n",
    "\n",
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "XARR1 = []\n",
    "XARR2 = []\n",
    "\n",
    "y = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "\n",
    "        XARR1.append([cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], 0, 0])\n",
    "        XARR2.append([cols[0], cols[1], cols[2], cols[3], 0, 0, cols[6], cols[7], cols[8], cols[9]])\n",
    "        y.append(cols[10])\n",
    "\n",
    "dt1 = tree.DecisionTreeClassifier(max_depth=3)\n",
    "dt1 = dt1.fit(XARR1, y)\n",
    "\n",
    "dt2 = tree.DecisionTreeClassifier(max_depth=3)\n",
    "dt2 = dt2.fit(XARR2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e538af2e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "X2 = []\n",
    "y2 = []\n",
    "\n",
    "bX = []\n",
    "bY = []\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "        EX = [cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]]\n",
    "        r1 = dt1.predict([EX])\n",
    "        r2 = dt2.predict([EX])\n",
    "        X2.append([r1[0], r2[0]])\n",
    "        y2.append(cols[10])\n",
    "\n",
    "clf3 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "clf3.fit(X2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04119437",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## AdaBoost\n",
    "Обучаем одно дерево на всем датасете, потом циклические обучаем новое дерево на основе полученные данных с предыдущего дерева и исходного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af43bdc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, shuffle=False)\n",
    "\n",
    "clf = AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=1), n_estimators=100)\n",
    "\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b14af2b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Using test_add dataset\n",
    "# ToDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ed9a3af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "        X.append([cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]])\n",
    "        y.append(cols[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f3b01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=1), n_estimators=100)\n",
    "\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56640ad7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "**жесткая классификация:** ответ решающего дерева - жесткий класс\n",
    "**мягкая классфикация:** ответ решающего дерева - массив с вероятностью класса\n",
    "**Регрессия:** дает грубый ответ, но действительный числа.\n",
    "\n",
    "Градиентный бустинг позволяет решать задачи регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4f7bf60",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "dataset = sd.load_boston()\n",
    "print(dataset.data.shape)\n",
    "print(dataset.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c28dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
