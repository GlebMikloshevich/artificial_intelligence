{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96dfd9b5",
   "metadata": {
    "trusted": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest\n",
    "1. Bagging - обучение дерева на датасете из случайных строк изначального датасета. Строки могут пересекаться, а могут не пересекаться\n",
    "2. Random subspaces - использует произвольные столбцы. Таким способом обучение происходит быстрее, а дерево становиться более устойчивым\n",
    "3. Random patches - использует произвольные строки и произвольные столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier, StackingClassifier, AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import sklearn.datasets as sd\n",
    "import sklearn.model_selection as sm\n",
    "import graphviz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "test_dat_path = '../datasets/test_add_forest.dat'\n",
    "\n",
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "XARR1 = []\n",
    "XARR2 = []\n",
    "XARR3 = []\n",
    "XARR4 = []\n",
    "XARR5 = []\n",
    "y = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "\n",
    "        XARR1.append([cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], 0, 0])\n",
    "        XARR2.append([cols[0], cols[1], cols[2], cols[3], 0, 0, cols[6], cols[7], cols[8], cols[9]])\n",
    "        XARR3.append([0, 0, cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]])\n",
    "        XARR4.append([0, cols[1], cols[2], 0, cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]])\n",
    "        XARR5.append([cols[0], cols[1], cols[2], cols[3], 0, cols[5], cols[6], cols[7], cols[8], cols[9]])\n",
    "        y.append(cols[10])\n",
    "\n",
    "dt1 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "dt1 = dt1.fit(XARR1, y)\n",
    "\n",
    "dt2 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "dt2 = dt2.fit(XARR2, y)\n",
    "\n",
    "dt3 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "dt3 = dt3.fit(XARR3, y)\n",
    "\n",
    "dt4 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "dt4 = dt4.fit(XARR4, y)\n",
    "\n",
    "dt5 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "dt5 = dt5.fit(XARR5, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.31963470319636 %\n",
      "good: 2861\n",
      "total: 4380\n"
     ]
    }
   ],
   "source": [
    "good = 0\n",
    "total = 0\n",
    "i = 0\n",
    "\n",
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "        EX = [cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]]\n",
    "        r1 = dt1.predict([EX])\n",
    "        r2 = dt2.predict([EX])\n",
    "        r3 = dt3.predict([EX])\n",
    "        r4 = dt4.predict([EX])\n",
    "        r5 = dt5.predict([EX])\n",
    "        z = int((int(r1[0]) + int(r2[0]) + int(r3[0]) + int(r4[0]) + int(r5[0])) / 5)\n",
    "\n",
    "        if z == int(cols[10]):\n",
    "            good += 1\n",
    "        total += 1\n",
    "\n",
    "print(str(good/ total * 100), '%')\n",
    "print(f'good: {good}')\n",
    "print(f'total: {total}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BaggingClassifier from sklearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8726027397260274\n"
     ]
    }
   ],
   "source": [
    "test_dat_path = '../datasets/test_add_forest.dat'\n",
    "\n",
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "        X.append([cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]])\n",
    "        y.append(cols[10])\n",
    "\n",
    "bagging_clf = BaggingClassifier(tree.DecisionTreeClassifier(max_depth=2), n_estimators=10)\n",
    "bagging_clf = bagging_clf.fit(X, y)\n",
    "\n",
    "print(bagging_clf.score(X, y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stacking\n",
    "**Stacking** - Для вычисления итогового результата обучается дополнительное решающее дерево, которое получает данные с деревьев первого этапа и выдает ответ"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "test_dat_path = '../datasets/test_add_forest.dat'\n",
    "\n",
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "XARR1 = []\n",
    "XARR2 = []\n",
    "\n",
    "y = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "\n",
    "        XARR1.append([cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], 0, 0])\n",
    "        XARR2.append([cols[0], cols[1], cols[2], cols[3], 0, 0, cols[6], cols[7], cols[8], cols[9]])\n",
    "        y.append(cols[10])\n",
    "\n",
    "dt1 = tree.DecisionTreeClassifier(max_depth=3)\n",
    "dt1 = dt1.fit(XARR1, y)\n",
    "\n",
    "dt2 = tree.DecisionTreeClassifier(max_depth=3)\n",
    "dt2 = dt2.fit(XARR2, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier(max_depth=2)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "X2 = []\n",
    "y2 = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "        EX = [cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]]\n",
    "        r1 = dt1.predict([EX])\n",
    "        r2 = dt2.predict([EX])\n",
    "        X2.append([r1[0], r2[0]])\n",
    "        y2.append(cols[10])\n",
    "\n",
    "clf3 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "clf3.fit(X2, y2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "good = 0\n",
    "total = 0\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "        EX = [cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]]\n",
    "        r1 = dt1.predict([EX])\n",
    "        r2 = dt2.predict([EX])\n",
    "        EX3 = [r1[0], r2[0]]\n",
    "        ans = clf3.predict([EX3])\n",
    "\n",
    "        if int(ans[0]) == int(cols[10]):\n",
    "            good += 1\n",
    "        total += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.20091324200914 %\n",
      "good: 3469\n",
      "total: 4380\n"
     ]
    }
   ],
   "source": [
    "print(str(good/ total * 100), '%')\n",
    "print(f'good: {good}')\n",
    "print(f'total: {total}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## StackingClassifier from sklearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9164383561643835\n"
     ]
    }
   ],
   "source": [
    "test_dat_path = '../datasets/test_add_forest.dat'\n",
    "\n",
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "XARR3 = []\n",
    "\n",
    "y3 = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "\n",
    "        XARR3.append([cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]])\n",
    "        y3.append(cols[10])\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=[('t1', tree.DecisionTreeClassifier(max_depth=5)),\n",
    "                                              ('t2', tree.DecisionTreeClassifier(max_depth=5)),\n",
    "                                              ('t3', tree.DecisionTreeClassifier(max_depth=5))],\n",
    "                                  final_estimator=tree.DecisionTreeClassifier(max_depth=2))\n",
    "\n",
    "stacking_clf = stacking_clf.fit(XARR3, y3)\n",
    "print(stacking_clf.score(XARR3, y3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Boosting\n",
    "**Boosting** - обучаем новое дерево, которое получает на вход исходный датасет и ответ с деревьев первого слоя"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Добавить код для бустинга"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "test_dat_path = '../datasets/test_add_forest.dat'\n",
    "\n",
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "XARR1 = []\n",
    "XARR2 = []\n",
    "\n",
    "y = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "\n",
    "        XARR1.append([cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], 0, 0])\n",
    "        XARR2.append([cols[0], cols[1], cols[2], cols[3], 0, 0, cols[6], cols[7], cols[8], cols[9]])\n",
    "        y.append(cols[10])\n",
    "\n",
    "dt1 = tree.DecisionTreeClassifier(max_depth=3)\n",
    "dt1 = dt1.fit(XARR1, y)\n",
    "\n",
    "dt2 = tree.DecisionTreeClassifier(max_depth=3)\n",
    "dt2 = dt2.fit(XARR2, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "X2 = []\n",
    "y2 = []\n",
    "\n",
    "bX = []\n",
    "bY = []\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "        EX = [cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]]\n",
    "        r1 = dt1.predict([EX])\n",
    "        r2 = dt2.predict([EX])\n",
    "        X2.append([r1[0], r2[0]])\n",
    "        y2.append(cols[10])\n",
    "\n",
    "clf3 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "clf3.fit(X2, y2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AdaBoost\n",
    "Обучаем одно дерево на всем датасете, потом циклические обучаем новое дерево на основе полученные данных с предыдущего дерева и исходного датасета"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "0.933"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, shuffle=False)\n",
    "\n",
    "clf = AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=1), n_estimators=100)\n",
    "\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using test_add dataset\n",
    "# ToDo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "f = open(test_dat_path, 'r')\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for line in f:\n",
    "    cols = line.split()\n",
    "    if cols:\n",
    "        EX = [cols[0], cols[1], cols[2], cols[3], cols[4], cols[5], cols[6], cols[7], cols[8], cols[9]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-65-549a2b0bc043>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mclf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mAdaBoostClassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtree\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDecisionTreeClassifier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_depth\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_estimators\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mclf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mclf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscore\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m         \u001B[0;31m# Fit\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 443\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_validate_estimator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    102\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"learning_rate must be greater than zero\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 104\u001B[0;31m         X, y = self._validate_data(X, y,\n\u001B[0m\u001B[1;32m    105\u001B[0m                                    \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'csr'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'csc'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m                                    \u001B[0mensure_2d\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    431\u001B[0m                 \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    432\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 433\u001B[0;31m                 \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    434\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    435\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m    869\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"y cannot be None\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    870\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 871\u001B[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001B[0m\u001B[1;32m    872\u001B[0m                     \u001B[0maccept_large_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maccept_large_sparse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    873\u001B[0m                     \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[1;32m    692\u001B[0m             \u001B[0;31m# If input is 1D raise error\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    693\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0marray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 694\u001B[0;31m                 raise ValueError(\n\u001B[0m\u001B[1;32m    695\u001B[0m                     \u001B[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    696\u001B[0m                     \u001B[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=1), n_estimators=100)\n",
    "\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "**жесткая классификация:** ответ решающего дерева - жесткий класс\n",
    "**мягкая классфикация:** ответ решающего дерева - массив с вероятностью класса\n",
    "**Регрессия:** дает грубый ответ, но действительный числа.\n",
    "\n",
    "Градиентный бустинг позволяет решать задачи регрессии"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "dataset = sd.load_boston()\n",
    "print(dataset.data.shape)\n",
    "print(dataset.target.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}